---
title: "LSTM 2"
author: "Annie Yang"
date: "10/10/2020"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
---

# 1.0 Libraries

```{r, warning=FALSE}
# Core Tidyverse
library(tidyverse)
library(glue)
library(forcats)

# Time Series
library(timetk)
library(tidyquant)
library(tibbletime)

# Visualization
library(cowplot)

# Preprocessing
library(recipes)

# Sampling / Accuracy
library(rsample)
library(yardstick) 

# Modeling
library(keras)
```

# 2.0 Data

```{r, warning=FALSE}
df <-  read.csv("D:/IIT-master/CS-571-Data Preparation & Analysis-master/project/diabetes_ds/sample_dat.csv", sep=",", header=T, stringsAsFactors = T)

value <- df$IMPUTED

db.date <- paste0(df$YEAR,'-',df$MONTH,'-',df$DAY)
db.time <- paste0(df$HOUR,':',df$MIN,':',df$SEC)


cgm_data <- data.frame(value)
cgm_data$index <-as.POSIXct(paste(db.date, db.time), format="%Y-%m-%d %H:%M:%S")

#Re-ordered
cgm_data <- cgm_data[colnames(cgm_data)[c(2, 1)]]

cgm_data <- as_tbl_time(cgm_data, index = index)


cgm_data
```

# 3.0 Exploratory Data Analysis

# 3.1 Visualizing Sunspot Data With Cowplot
```{r, fig.width=16, warning=FALSE, echo=FALSE, fig.height=12}
p1 <- cgm_data %>%
    filter_time("2019-08-01 00:00" ~ "2019-08-31 00:00") %>%
    ggplot(aes(index, value)) +
    geom_point(color = palette_light()[[1]], alpha = 5, size=1) +
    theme_tq() +
    labs(
        title = "From Aug 1st to Aug 31st"
    )
p2 <- cgm_data %>%
    filter_time("2019-08-01 00:00" ~ "2019-08-05 00:00") %>%
    ggplot(aes(index, value)) +
    geom_line(color = palette_light()[[1]], alpha = 0.1) +
    geom_point(color = palette_light()[[1]]) +
    geom_smooth(method = "loess", span = 0.2, se = FALSE) +
    theme_tq() +
    labs(
        title = "From Aug 1st to Aug 7nd (One week data)"
    )

p_title <- ggdraw() + 
    draw_label("CGM dataset 2019", size = 18, fontface = "bold", colour = palette_light()[[1]])
plot_grid(p_title, p1, p2, ncol = 1, rel_heights = c(0.1, 1, 1))
```

# 3.2 Evaluating The ACF
```{r}
tidy_acf <- function(data, value, lags = 0:20) {
    
    value_expr <- enquo(value)
    
    acf_values <- data %>%
        pull(value) %>%
        acf(lag.max = tail(lags, 1), plot = FALSE) %>%
        .$acf %>%
        .[,,1]
    
    ret <- tibble(acf = acf_values) %>%
        rowid_to_column(var = "lag") %>%
        mutate(lag = lag - 1) %>%
        filter(lag %in% lags)
    
    return(ret)
}
```


```{r}
cgm_data <- cgm_data %>%
    filter_time("2019-08-05 00:00" ~ "2019-08-15 00:00") 

max_lag <- 1000

cgm_data %>%
    tidy_acf(value, lags = 0:max_lag)
```

```{r}
cgm_data %>%
    tidy_acf(value, lags = 0:max_lag) %>%
    ggplot(aes(lag, acf)) +
    geom_segment(aes(xend = lag, yend = 0), color = palette_light()[[1]]) +
    #geom_vline(xintercept = 2016, size = 3, color = palette_light()[[2]]) +
    #annotate("text", label = "1 Week Mark", x = 130, y = 0.8, 
    #         color = palette_light()[[2]], size = 3, hjust = 0) +
    theme_tq() +
    labs(title = "ACF: CGM ")
```

```{r}
cgm_data %>%
    tidy_acf(value, lags = 0:350) %>%
    ggplot(aes(lag, acf)) +
    #geom_vline(xintercept = 120, size = 3, color = palette_light()[[2]]) +
    geom_segment(aes(xend = lag, yend = 0), color = palette_light()[[1]]) +
    geom_point(color = palette_light()[[1]], size = 2) +
    #geom_label(aes(label = acf %>% round(2)), vjust = -1,
    #          color = palette_light()[[1]]) +
    #annotate("text", label = "10 Year Mark", x = 121, y = 0.8, 
    #         color = palette_light()[[2]], size = 5, hjust = 0) +
    theme_tq() +
    labs(title = "ACF: CGM")
#, subtitle = "Zoomed in on Lags 115 to 135")
```

```{r}
optimal_lag_setting <- cgm_data %>%
    tidy_acf(value, lags = 300:350) %>%
    filter(acf == max(acf)) %>%
    pull(lag)

optimal_lag_setting
```

# 4.0 Backtesting: Time Series Cross Validation

# 4.1 Developing A Backtesting Strategy

```{r, warning=FALSE, echo=FALSE}
periods_train <- 12*36# 1 days
periods_test  <- 12*4 # 2 hours
skip_span     <- 12 * 36

rolling_origin_resamples <- rolling_origin(
    cgm_data,
    initial    = periods_train,
    assess     = periods_test,
    cumulative = FALSE,
    skip       = skip_span
)

rolling_origin_resamples
```

```{r}
# Plotting function for a single split
plot_split <- function(split, expand_y_axis = TRUE, alpha = 1, size = 1, base_size = 14) {
    
    # Manipulate data
    train_tbl <- training(split) %>%
        add_column(key = "training") 
    
    test_tbl  <- testing(split) %>%
        add_column(key = "testing") 
    
    data_manipulated <- bind_rows(train_tbl, test_tbl) %>%
        as_tbl_time(index = index) %>%
        mutate(key = fct_relevel(key, "training", "testing"))
    
    # Collect attributes
    train_time_summary <- train_tbl %>%
        tk_index() %>%
        tk_get_timeseries_summary()
    
    test_time_summary <- test_tbl %>%
        tk_index() %>%
        tk_get_timeseries_summary()
    
    # Visualize
    g <- data_manipulated %>%
        ggplot(aes(x = index, y = value, color = key)) +
        geom_line(size = size, alpha = alpha) +
        theme_tq(base_size = base_size) +
        scale_color_tq() +
        labs(
            title    = glue("Split: {split$id}"),
            subtitle = glue("{train_time_summary$start} to {test_time_summary$end}"),
            y = "", x = ""
        ) +
        theme(legend.position = "none") 
    
    
    
    return(g)
}
```

```{r, warning=FALSE}
rolling_origin_resamples$splits[[1]] %>%
    plot_split() +
    theme(legend.position = "bottom")
```


```{r}
# Plotting function that scales to all splits 
plot_sampling_plan <- function(sampling_tbl, expand_y_axis = TRUE, 
                               ncol = 3, alpha = 1, size = 1, base_size = 14, 
                               title = "Sampling Plan") {
    
    # Map plot_split() to sampling_tbl
    sampling_tbl_with_plots <- sampling_tbl %>%
        mutate(gg_plots = map(splits, plot_split, 
                              expand_y_axis = expand_y_axis,
                              alpha = alpha, base_size = base_size))
    
    # Make plots with cowplot
    plot_list <- sampling_tbl_with_plots$gg_plots 
    
    p_temp <- plot_list[[1]] + theme(legend.position = "bottom")
    legend <- get_legend(p_temp)
    
    p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)
    
    p_title <- ggdraw() + 
        draw_label(title, size = 18, fontface = "bold", colour = palette_light()[[1]])
    
    g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))
    
    return(g)
    
}
```

```{r}
rolling_origin_resamples %>%
    plot_sampling_plan(expand_y_axis = T, ncol = 3, alpha = 1, size = 1, base_size = 10, 
                       title = "Backtesting Strategy: Rolling Origin Sampling Plan")
```

# 5.0 Modeling The Keras Stateful LSTM Model

#5.1 Single LSTM
```{r}
split    <- rolling_origin_resamples$splits[[1]]
split_id <- rolling_origin_resamples$id[[1]]
```

# 5.1.1 Visualizing The Split
```{r}
plot_split(split, expand_y_axis = FALSE, size = 1) +
    theme(legend.position = "bottom") +
    ggtitle(glue("Split: {split_id}"))
```

# 5.1.2 Data Setup
```{r, warning=FALSE}
df_trn <- training(split)
df_tst <- testing(split)
df <- bind_rows(
    df_trn %>% add_column(key = "training"),
    df_tst %>% add_column(key = "testing")
) %>% 
    as_tbl_time(index = index)
df
```

# 5.1.3 Preprocessing With Recipes
```{r}
rec_obj <- recipe(value ~ ., df) %>%
    step_sqrt(value) %>%
    step_center(value) %>%
    step_scale(value) %>%
    prep()
df_processed_tbl <- bake(rec_obj, df)
df_processed_tbl
```

```{r}
center_history <- rec_obj$steps[[2]]$means["value"]
scale_history  <- rec_obj$steps[[3]]$sds["value"]
c("center" = center_history, "scale" = scale_history)
```

# 5.1.4 LSTM Plan
```{r}
# Model inputs
lag_setting  <- nrow(df_tst)
batch_size   <- 6
train_length <- 12*36
tsteps       <- 1
epochs       <- 80
```

# 5.1.5 2D And 3D Train/Test Arrays
```{r}
# Training Set
lag_train_tbl <- df_processed_tbl %>%
    mutate(value_lag = lag(value, n = lag_setting)) %>%
    filter(!is.na(value_lag)) %>%
    filter(key == "training") %>%
    tail(train_length)
x_train_vec <- lag_train_tbl$value_lag
x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))
y_train_vec <- lag_train_tbl$value
y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))
# Testing Set
lag_test_tbl <- df_processed_tbl %>%
    mutate(
        value_lag = lag(value, n = lag_setting)
    ) %>%
    filter(!is.na(value_lag)) %>%
    filter(key == "testing")
x_test_vec <- lag_test_tbl$value_lag
x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))
y_test_vec <- lag_test_tbl$value
y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))
```

# 5.1.6 Building The LSTM Model
```{r, warning=FALSE}
model <- NULL

create_model <- function(){
  keras_model_sequential() %>%
    layer_lstm(units            = 1, 
               input_shape      = c(tsteps, 1), 
               batch_size       = batch_size,
               return_sequences = TRUE, 
               stateful         = TRUE) %>% 
    #layer_lstm(units            = 8, 
    #          batch_size       = batch_size,
    #           return_sequences = TRUE, 
    #           stateful         = TRUE) %>% 
    layer_dense(units = 64, activation = 'tanh') %>%
    layer_dense(units = 48, activation = 'relu') %>%
    layer_dense(units = 48, activation = 'tanh') %>%
    compile(loss = 'mae', optimizer = 'adam')
}

model <- create_model()

model
```

# 5.1.7 Fitting The LSTM Model
```{r}
for (i in 1:epochs) {
    model %>% fit(x          = x_train_arr, 
                  y          = y_train_arr, 
                  batch_size = batch_size,
                  epochs     = 1, 
                  verbose    = 1, 
                  shuffle    = FALSE)
    
    model %>% reset_states()
    cat("Epoch: ", i)
    
}
```

# 5.1.8 Predicting Using The LSTM Model
```{r, warning=FALSE}
# Make Predictions
pred_out <- model %>% 
    predict(x_test_arr, batch_size = batch_size)%>%
    .[,1,48]

# Retransform values
pred_tbl <- tibble(
    index   = lag_test_tbl$index,
    value   = (pred_out * scale_history + center_history)^2
) 
# Combine actual data with predictions
tbl_1 <- df_trn %>%
    add_column(key = "actual")
tbl_2 <- df_tst %>%
    add_column(key = "actual")
tbl_3 <- pred_tbl %>%
    add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
    index_expr <- enquo(index)
    bind_rows(data_1, data_2) %>%
        as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
    reduce(time_bind_rows, index = index) %>%
    arrange(key, index) %>%
    mutate(key = as_factor(key))
ret
```

# 5.1.9 Assessing Performance Of The LSTM On A Single Split
```{r}
calc_rmse <- function(prediction_tbl) {
    
    rmse_calculation <- function(data) {
        data %>%
            spread(key = key, value = value) %>%
            select(-index) %>%
            filter(!is.na(predict)) %>%
            rename(
                truth    = actual,
                estimate = predict
            ) %>%
            rmse(truth, estimate)
    }
    
    safe_rmse <- possibly(rmse_calculation, otherwise = NA)
    
    safe_rmse(prediction_tbl)
        
}
```

```{r}
calc_rmse(ret)$.estimate
```

# 5.1.10 Visualizing The Single Prediction
```{r}
# Setup single plot function
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
    
    rmse_val <- calc_rmse(data)$.estimate
    
    g <- data %>%
        ggplot(aes(index, value, color = key)) +
        geom_point(alpha = alpha, size = size) + 
        theme_tq(base_size = base_size) +
        scale_color_tq() +
        theme(legend.position = "none") +
        labs(
            title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
            x = "", y = ""
        )
    
    return(g)
}
```

```{r, fig.width=12}
ret %>% 
    plot_prediction(id = split_id, alpha = 0.5) +
    theme(legend.position = "bottom")
```
# 5.2 Backtesting The LSTM On All Eleven Samples

# 5.2.1 Creating An LSTM Prediction Function

```{r}
predict_keras_lstm <- function(split, epochs = 80, ...) {
    
    lstm_prediction <- function(split, epochs, ...) {
        
        # 5.1.2 Data Setup
        df_trn <- training(split)
        df_tst <- testing(split)
        
        df <- bind_rows(
            df_trn %>% add_column(key = "training"),
            df_tst %>% add_column(key = "testing")
        ) %>% 
            as_tbl_time(index = index)
        
        # 5.1.3 Preprocessing
        rec_obj <- recipe(value ~ ., df) %>%
            step_sqrt(value) %>%
            step_center(value) %>%
            step_scale(value) %>%
            prep()
        
        df_processed_tbl <- bake(rec_obj, df)
        
        center_history <- rec_obj$steps[[2]]$means["value"]
        scale_history  <- rec_obj$steps[[3]]$sds["value"]
        
        # 5.1.4 LSTM Plan
        lag_setting  <- nrow(df_tst)
        batch_size   <- 6
        train_length <- 12*36
        tsteps       <- 1
        epochs       <- epochs
        
        # 5.1.5 Train/Test Setup
        lag_train_tbl <- df_processed_tbl %>%
            mutate(value_lag = lag(value, n = lag_setting)) %>%
            filter(!is.na(value_lag)) %>%
            filter(key == "training") %>%
            tail(train_length)
        
        x_train_vec <- lag_train_tbl$value_lag
        x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))
        
        y_train_vec <- lag_train_tbl$value
        y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))
        
        lag_test_tbl <- df_processed_tbl %>%
            mutate(
                value_lag = lag(value, n = lag_setting)
            ) %>%
            filter(!is.na(value_lag)) %>%
            filter(key == "testing")
        
        x_test_vec <- lag_test_tbl$value_lag
        x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))
        
        y_test_vec <- lag_test_tbl$value
        y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))
                
        # 5.1.6 LSTM Model
        model <- NULL
        model <- create_model()
        
        # 5.1.7 Fitting LSTM
        for (i in 1:epochs) {
            model %>% fit(x          = x_train_arr, 
                          y          = y_train_arr, 
                          batch_size = batch_size,
                          epochs     = 1, 
                          verbose    = 1, 
                          shuffle    = FALSE)
            
            model %>% reset_states()
            cat("Epoch: ", i)
            
        }
        
        # 5.1.8 Predict and Return Tidy Data
        # Make Predictions
        pred_out <- model %>% 
            predict(x_test_arr, batch_size = batch_size) %>%
            .[,1,48] 
        
        # Retransform values
        pred_tbl <- tibble(
            index   = lag_test_tbl$index,
            value   = (pred_out * scale_history + center_history)^2
        ) 
        
        # Combine actual data with predictions
        tbl_1 <- df_trn %>%
            add_column(key = "actual")
        
        tbl_2 <- df_tst %>%
            add_column(key = "actual")
        
        tbl_3 <- pred_tbl %>%
            add_column(key = "predict")
        
        # Create time_bind_rows() to solve dplyr issue
        time_bind_rows <- function(data_1, data_2, index) {
            index_expr <- enquo(index)
            bind_rows(data_1, data_2) %>%
                as_tbl_time(index = !! index_expr)
        }
        
        ret <- list(tbl_1, tbl_2, tbl_3) %>%
            reduce(time_bind_rows, index = index) %>%
            arrange(key, index) %>%
            mutate(key = as_factor(key))

        return(ret)
        
    }
    
    safe_lstm <- possibly(lstm_prediction, otherwise = NA)
    
    safe_lstm(split, epochs, ...)
    
}
```

```{r, warning=FALSE}
predict_keras_lstm(split, epochs = 80)
```

# 5.2.2 Mapping The LSTM Prediction Function Over The 8 Samples

```{r}
sample_predictions_lstm_tbl <- rolling_origin_resamples %>%
     mutate(predict = map(splits, predict_keras_lstm, epochs = 80))
```

```{r}
sample_predictions_lstm_tbl
```

# 5.2.3 Assessing The Backtested Performance

```{r, warning=FALSE}
rmse <-matrix()
for (i in 1:6) {
  rmse[i] <- calc_rmse(sample_predictions_lstm_tbl$predict[[i]])$.estimate
}

print(rmse)
sample_predictions_lstm_tbl$rmse <- rmse

sample_rmse_tbl<- sample_predictions_lstm_tbl %>%
  select(id, rmse)

sample_rmse_tbl

```

```{r,fig.width=12}
sample_rmse_tbl %>%
    ggplot(aes(rmse)) +
    geom_histogram(aes(y = ..density..), fill = palette_light()[[1]], bins = 18) +
    geom_density(fill = palette_light()[[1]], alpha = 0.4) +
    theme_tq() +
    ggtitle("Histogram of RMSE")
```

```{r}
sample_rmse_tbl %>%
    summarize(
        mean_rmse = mean(rmse),
        sd_rmse   = sd(rmse)
    )
```

# 5.2.4 Visualizing The Backtest Results
```{r}
plot_predictions <- function(sampling_tbl, predictions_col, 
                             ncol = 3, alpha = 1, size = 2, base_size = 14,
                             title = "Backtested Predictions") {
    
    predictions_col_expr <- enquo(predictions_col)
    
    # Map plot_split() to sampling_tbl
    sampling_tbl_with_plots <- sampling_tbl %>%
        mutate(gg_plots = map2(!! predictions_col_expr, id, 
                               .f        = plot_prediction, 
                               alpha     = alpha, 
                               size      = size, 
                               base_size = base_size)) 
    
    # Make plots with cowplot
    plot_list <- sampling_tbl_with_plots$gg_plots 
    
    p_temp <- plot_list[[1]] + theme(legend.position = "bottom")
    legend <- get_legend(p_temp)
    
    p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)
    
    
    
    p_title <- ggdraw() + 
        draw_label(title, size = 18, fontface = "bold", colour = palette_light()[[1]])
    
    g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))
    
    return(g)
    
}
```

```{r, fig.width=10}
sample_predictions_lstm_tbl %>%
    plot_predictions(predictions_col = predict, alpha = 0.5, size = 1, base_size = 10,
                     title = "Keras Stateful LSTM: Backtested Predictions")
```














