y_test_vec <- lag_test_tbl$value
y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))
# 5.1.6 LSTM Model
model <- NULL
model <- create_model()
# 5.1.7 Fitting LSTM
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# 5.1.8 Predict and Return Tidy Data
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1,48]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
value   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- df_trn %>%
add_column(key = "actual")
tbl_2 <- df_tst %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
return(ret)
}
safe_lstm <- possibly(lstm_prediction, otherwise = NA)
safe_lstm(split, epochs, ...)
}
predict_keras_lstm(split, epochs = 80)
sample_predictions_lstm_tbl <- rolling_origin_resamples %>%
mutate(predict = map(splits, predict_keras_lstm, epochs = 80))
# Core Tidyverse
library(tidyverse)
library(glue)
library(forcats)
# Time Series
library(timetk)
library(tidyquant)
library(tibbletime)
# Visualization
library(cowplot)
# Preprocessing
library(recipes)
# Sampling / Accuracy
library(rsample)
library(yardstick)
# Modeling
library(keras)
set.seed(12)
df <-  read.csv("D:/IIT-master/CS-571-Data Preparation & Analysis-master/project/diabetes_ds/sample_dat.csv", sep=",", header=T, stringsAsFactors = T)
value <- df$IMPUTED
db.date <- paste0(df$YEAR,'-',df$MONTH,'-',df$DAY)
db.time <- paste0(df$HOUR,':',df$MIN,':',df$SEC)
cgm_data <- data.frame(value)
cgm_data$index <-as.POSIXct(paste(db.date, db.time), format="%Y-%m-%d %H:%M:%S")
#Re-ordered
cgm_data <- cgm_data[colnames(cgm_data)[c(2, 1)]]
cgm_data <- as_tbl_time(cgm_data, index = index)
cgm_data
p1 <- cgm_data %>%
filter_time("2019-08-01 00:00" ~ "2019-08-31 00:00") %>%
ggplot(aes(index, value)) +
geom_point(color = palette_light()[[1]], alpha = 5, size=1) +
theme_tq() +
labs(
title = "From Aug 1st to Aug 31st"
)
p2 <- cgm_data %>%
filter_time("2019-08-05 00:00" ~ "2019-08-15 00:00") %>%
ggplot(aes(index, value)) +
geom_line(color = palette_light()[[1]], alpha = 0.1) +
geom_point(color = palette_light()[[1]]) +
geom_smooth(method = "loess", span = 0.2, se = FALSE) +
theme_tq() +
labs(
title = "From Aug 5th to Aug 15th (10 days data)"
)
p_title <- ggdraw() +
draw_label("CGM dataset 2019", size = 18, fontface = "bold", colour = palette_light()[[1]])
plot_grid(p_title, p1, p2, ncol = 1, rel_heights = c(0.1, 1, 1))
tidy_acf <- function(data, value, lags = 0:20) {
value_expr <- enquo(value)
acf_values <- data %>%
pull(value) %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
ret <- tibble(acf = acf_values) %>%
rowid_to_column(var = "lag") %>%
mutate(lag = lag - 1) %>%
filter(lag %in% lags)
return(ret)
}
cgm_data <- cgm_data %>%
filter_time("2019-08-05 00:00" ~ "2019-08-15 00:00")
max_lag <- 1000
cgm_data %>%
tidy_acf(value, lags = 0:max_lag)
cgm_data %>%
tidy_acf(value, lags = 0:max_lag) %>%
ggplot(aes(lag, acf)) +
geom_segment(aes(xend = lag, yend = 0), color = palette_light()[[1]]) +
#geom_vline(xintercept = 2016, size = 3, color = palette_light()[[2]]) +
#annotate("text", label = "1 Week Mark", x = 130, y = 0.8,
#         color = palette_light()[[2]], size = 3, hjust = 0) +
theme_tq() +
labs(title = "ACF: CGM ")
cgm_data %>%
tidy_acf(value, lags = 0:350) %>%
ggplot(aes(lag, acf)) +
#geom_vline(xintercept = 120, size = 3, color = palette_light()[[2]]) +
geom_segment(aes(xend = lag, yend = 0), color = palette_light()[[1]]) +
geom_point(color = palette_light()[[1]], size = 2) +
#geom_label(aes(label = acf %>% round(2)), vjust = -1,
#          color = palette_light()[[1]]) +
#annotate("text", label = "10 Year Mark", x = 121, y = 0.8,
#         color = palette_light()[[2]], size = 5, hjust = 0) +
theme_tq() +
labs(title = "ACF: CGM")
#, subtitle = "Zoomed in on Lags 115 to 135")
optimal_lag_setting <- cgm_data %>%
tidy_acf(value, lags = 300:350) %>%
filter(acf == max(acf)) %>%
pull(lag)
#optimal_lag_setting
periods_train <- 12*36# 1.5 days
periods_test  <- 12*4 # 4 hours
skip_span     <- 12 * 40
rolling_origin_resamples <- rolling_origin(
cgm_data,
initial    = periods_train,
assess     = periods_test,
cumulative = FALSE,
skip       = skip_span
)
rolling_origin_resamples
# Plotting function for a single split
plot_split <- function(split, expand_y_axis = TRUE, alpha = 1, size = 1, base_size = 14) {
# Manipulate data
train_tbl <- training(split) %>%
add_column(key = "training")
test_tbl  <- testing(split) %>%
add_column(key = "testing")
data_manipulated <- bind_rows(train_tbl, test_tbl) %>%
as_tbl_time(index = index) %>%
mutate(key = fct_relevel(key, "training", "testing"))
# Collect attributes
train_time_summary <- train_tbl %>%
tk_index() %>%
tk_get_timeseries_summary()
test_time_summary <- test_tbl %>%
tk_index() %>%
tk_get_timeseries_summary()
# Visualize
g <- data_manipulated %>%
ggplot(aes(x = index, y = value, color = key)) +
geom_line(size = size, alpha = alpha) +
theme_tq(base_size = base_size) +
scale_color_tq() +
labs(
title    = glue("Split: {split$id}"),
subtitle = glue("{train_time_summary$start} to {test_time_summary$end}"),
y = "", x = ""
) +
theme(legend.position = "none")
return(g)
}
rolling_origin_resamples$splits[[1]] %>%
plot_split() +
theme(legend.position = "bottom")
# Plotting function that scales to all splits
plot_sampling_plan <- function(sampling_tbl, expand_y_axis = TRUE,
ncol = 3, alpha = 1, size = 1, base_size = 14,
title = "Sampling Plan") {
# Map plot_split() to sampling_tbl
sampling_tbl_with_plots <- sampling_tbl %>%
mutate(gg_plots = map(splits, plot_split,
expand_y_axis = expand_y_axis,
alpha = alpha, base_size = base_size))
# Make plots with cowplot
plot_list <- sampling_tbl_with_plots$gg_plots
p_temp <- plot_list[[1]] + theme(legend.position = "bottom")
legend <- get_legend(p_temp)
p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)
p_title <- ggdraw() +
draw_label(title, size = 18, fontface = "bold", colour = palette_light()[[1]])
g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))
return(g)
}
rolling_origin_resamples %>%
plot_sampling_plan(expand_y_axis = T, ncol = 3, alpha = 1, size = 1, base_size = 10,
title = "Backtesting Strategy: Rolling Origin Sampling Plan")
split    <- rolling_origin_resamples$splits[[1]]
split_id <- rolling_origin_resamples$id[[1]]
plot_split(split, expand_y_axis = FALSE, size = 1) +
theme(legend.position = "bottom") +
ggtitle(glue("Split: {split_id}"))
df_trn <- training(split)
df_tst <- testing(split)
df <- bind_rows(
df_trn %>% add_column(key = "training"),
df_tst %>% add_column(key = "testing")
) %>%
as_tbl_time(index = index)
df
rec_obj <- recipe(value ~ ., df) %>%
step_sqrt(value) %>%
step_center(value) %>%
step_scale(value) %>%
prep()
df_processed_tbl <- bake(rec_obj, df)
df_processed_tbl
center_history <- rec_obj$steps[[2]]$means["value"]
scale_history  <- rec_obj$steps[[3]]$sds["value"]
c("center" = center_history, "scale" = scale_history)
# Model inputs
lag_setting  <- nrow(df_tst)
batch_size   <- 6
train_length <- 12*36
tsteps       <- 1
epochs       <- 100
# Training Set
lag_train_tbl <- df_processed_tbl %>%
mutate(value_lag = lag(value, n = lag_setting)) %>%
filter(!is.na(value_lag)) %>%
filter(key == "training") %>%
tail(train_length)
x_train_vec <- lag_train_tbl$value_lag
x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))
y_train_vec <- lag_train_tbl$value
y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))
# Testing Set
lag_test_tbl <- df_processed_tbl %>%
mutate(
value_lag = lag(value, n = lag_setting)
) %>%
filter(!is.na(value_lag)) %>%
filter(key == "testing")
x_test_vec <- lag_test_tbl$value_lag
x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))
y_test_vec <- lag_test_tbl$value
y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))
model <- NULL
create_model <- function(){
keras_model_sequential() %>%
layer_lstm(units            = 1,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dense(units = 28, activation = 'tanh')%>%
layer_dense(units = 8, activation = 'relu')%>%
layer_dense(units = 48, activation = 'tanh')%>%
layer_dense(units = 48, activation = 'tanh')%>%
compile(loss = 'mae', optimizer = 'adam')
}
model <- create_model()
model
set.seed(12)
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
set.seed(12)
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size)%>%
.[,1,48]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
value   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- df_trn %>%
add_column(key = "actual")
tbl_2 <- df_tst %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
ret
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = value) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
calc_rmse(ret)$.estimate
# Setup single plot function
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 12) {
rmse_val <- calc_rmse(data)$.estimate
g <- data %>%
ggplot(aes(index, value, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(id = split_id, alpha = 0.5) +
theme(legend.position = "bottom")
predict_keras_lstm <- function(split, epochs = 80, ...) {
lstm_prediction <- function(split, epochs, ...) {
# 5.1.2 Data Setup
df_trn <- training(split)
df_tst <- testing(split)
df <- bind_rows(
df_trn %>% add_column(key = "training"),
df_tst %>% add_column(key = "testing")
) %>%
as_tbl_time(index = index)
# 5.1.3 Preprocessing
rec_obj <- recipe(value ~ ., df) %>%
step_sqrt(value) %>%
step_center(value) %>%
step_scale(value) %>%
prep()
df_processed_tbl <- bake(rec_obj, df)
center_history <- rec_obj$steps[[2]]$means["value"]
scale_history  <- rec_obj$steps[[3]]$sds["value"]
# 5.1.4 LSTM Plan
lag_setting  <- nrow(df_tst)
batch_size   <- 6
train_length <- 12*36
tsteps       <- 1
epochs       <- epochs
# 5.1.5 Train/Test Setup
lag_train_tbl <- df_processed_tbl %>%
mutate(value_lag = lag(value, n = lag_setting)) %>%
filter(!is.na(value_lag)) %>%
filter(key == "training") %>%
tail(train_length)
x_train_vec <- lag_train_tbl$value_lag
x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))
y_train_vec <- lag_train_tbl$value
y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))
lag_test_tbl <- df_processed_tbl %>%
mutate(
value_lag = lag(value, n = lag_setting)
) %>%
filter(!is.na(value_lag)) %>%
filter(key == "testing")
x_test_vec <- lag_test_tbl$value_lag
x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))
y_test_vec <- lag_test_tbl$value
y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))
# 5.1.6 LSTM Model
model <- NULL
model <- create_model()
# 5.1.7 Fitting LSTM
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# 5.1.8 Predict and Return Tidy Data
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1,48]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
value   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- df_trn %>%
add_column(key = "actual")
tbl_2 <- df_tst %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
return(ret)
}
safe_lstm <- possibly(lstm_prediction, otherwise = NA)
safe_lstm(split, epochs, ...)
}
predict_keras_lstm(split, epochs = 80)
sample_predictions_lstm_tbl <- rolling_origin_resamples %>%
mutate(predict = map(splits, predict_keras_lstm, epochs = 80))
rmse <-matrix()
for (i in 1:5) {
rmse[i] <- calc_rmse(sample_predictions_lstm_tbl$predict[[i]])$.estimate
}
print(rmse)
sample_predictions_lstm_tbl$rmse <- rmse
sample_rmse_tbl<- sample_predictions_lstm_tbl %>%
select(id, rmse)
#sample_rmse_tbl
sample_rmse_tbl %>%
summarize(
mean_rmse = mean(rmse),
sd_rmse   = sd(rmse)
)
plot_predictions <- function(sampling_tbl, predictions_col,
ncol = 3, alpha = 1, size = 2, base_size = 14,
title = "Backtested Predictions") {
predictions_col_expr <- enquo(predictions_col)
# Map plot_split() to sampling_tbl
sampling_tbl_with_plots <- sampling_tbl %>%
mutate(gg_plots = map2(!! predictions_col_expr, id,
.f        = plot_prediction,
alpha     = alpha,
size      = size,
base_size = base_size))
# Make plots with cowplot
plot_list <- sampling_tbl_with_plots$gg_plots
p_temp <- plot_list[[1]] + theme(legend.position = "bottom")
legend <- get_legend(p_temp)
p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)
p_title <- ggdraw() +
draw_label(title, size = 18, fontface = "bold", colour = palette_light()[[1]])
g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))
return(g)
}
sample_predictions_lstm_tbl %>%
plot_predictions(predictions_col = predict, alpha = 0.5, size = 1, base_size = 12,
title = "Keras Stateful LSTM: Backtested Predictions")
getPerformance = function(pred, val) {
res = pred - val
MAE = sum(abs(res))/length(val)
RSS = sum(res^2)
MSE = RSS/length(val)
RMSE = sqrt(MSE)
perf = data.frame(MAE, RSS, MSE, RMSE)
}
res_perf <- list()
for (i in 1:5) {
res_perf[[i]] <- getPerformance(sample_predictions_lstm_tbl$predict[[i]]$value[481:528], sample_predictions_lstm_tbl$predict[[i]]$value[433:480])
}
res_perf
mae.val = 0
rss.val = 0
mse.val = 0
rmse.val = 0
for (i in 1:5) {
mae.val = mae.val+res_perf[[i]][,1]
rss.val = rss.val+res_perf[[i]][,2]
mse.val = mse.val+res_perf[[i]][,3]
rmse.val = rmse.val+res_perf[[i]][,4]
}
mae.val/5
rss.val/5
mse.val/5
rmse.val/5
#avg.perf = data.frame(mae.val/5, rss.val/5, mse.val/5, rmse.val/5)
#show(avg.perf)
