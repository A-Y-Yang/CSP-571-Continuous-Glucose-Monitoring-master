---
title: "Time series - ARIMA model"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
author: Annie Yang
---

# `Load` the data set (*.csv file) & Extract the `IMPUTED` column.
```{r}
df <-  read.csv("D:/IIT-master/CS-571-Data Preparation & Analysis-master/project/diabetes_ds/sample_dat.csv", sep=",", header=T, stringsAsFactors = T)

glu_level<- df$IMPUTED
diabetes.df <- data.frame(glu_level)
sum(is.na(diabetes.df))
#View(diabetes.df)
```

Have `524` missing values.

# Combine columns to form the `timestamp` as the `Date Object`.
```{r}
db.date <- paste0(df$YEAR,'-',df$MONTH,'-',df$DAY)
db.time <- paste0(df$HOUR,':',df$MIN,':',df$SEC)

diabetes.df$date_time <- as.POSIXct(paste(db.date, db.time), format="%Y-%m-%d %H:%M:%S")

#diabetes.df$Date <- as.Date(db.date)
#Re-ordered
diabetes.df <- diabetes.df[colnames(diabetes.df)[c(2, 1)]]

head(diabetes.df)
tail(diabetes.df)
```

## Take substes (by Month)
```{r}
ts.Feb = subset(diabetes.df, date_time >= as.POSIXct("2019-02-01 00:00") & date_time < as.POSIXct("2019-03-01 00:00"))
sum(is.na(ts.Feb))
ts.Mar = subset(diabetes.df, date_time >= as.POSIXct("2019-03-01 00:00") & date_time < as.POSIXct("2019-03-02 00:00"))
sum(is.na(ts.Mar))
ts.Aprl = subset(diabetes.df, date_time >= as.POSIXct("2019-04-01 00:00") & date_time < as.POSIXct("2019-05-01 00:00"))
sum(is.na(ts.Aprl))
ts.May = subset(diabetes.df, date_time >= as.POSIXct("2019-05-05 00:00") & date_time < as.POSIXct("2019-06-01 00:00"))
sum(is.na(ts.May))
ts.June = subset(diabetes.df, date_time >= as.POSIXct("2019-06-01 00:00") & date_time < as.POSIXct("2019-07-01 00:00"))
sum(is.na(ts.June))
ts.July = subset(diabetes.df, date_time >= as.POSIXct("2019-07-01 00:00") & date_time < as.POSIXct("2019-08-01 00:00"))
sum(is.na(ts.July))
ts.84 = subset(diabetes.df, date_time >= as.POSIXct("2019-08-01 00:00") & date_time < as.POSIXct("2019-08-04 00:00"))
sum(is.na(ts.84))
#ts.Feb

```

Choose the ts data in March OR August, I'll choose August since it has more data points.

```{r}
dim(ts.Mar)
dim(ts.84)
```

# `Data Overview`

## `Raw Data Visualization`
```{r, warning=FALSE, fig.width=20, fig.height=6}
library(ggplot2)
library(dplyr)

# Most basic bubble plot
#p2 <- ggplot(ts.Mar, aes(x=date_time, y=glu_level)) +
#  geom_line() + 
#  xlab("")

p.raw <- ggplot(ts.Mar, aes(x=date_time, y=glu_level)) +
          geom_line(na.rm=TRUE) +  
         ggtitle("Continuous Glucose Monitoring 2019-01-26 ~ 2019-09-29") +
         xlab("Time") + ylab("Imputed BG level") +
         theme(plot.title = element_text(lineheight=.8, face="bold", 
                                        size = 20)) +
         theme(text = element_text(size=18))
p.raw
```

```{r, fig.width=20, fig.height=6}
p2 <- p.raw + stat_smooth(colour="green")

p2
```

```{r}
t = ts.Mar$glu_level
y_stationary <- rnorm(length(t),mean=1,sd=1) # the stationary time series (ts)
y_trend      <- cumsum(rnorm(length(t),mean=1,sd=4))+t/100 # our ts with a trend
# lets normalize each for simplicity
y_stationary<- y_stationary/max(y_stationary) 
y_trend      <- y_trend/max(y_trend) 
```

```{r}
plot.new()
frame()
par(mfcol=c(2,2))
# the stationary signal and ACF
plot(t,y_stationary,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Stationary signal")
acf(y_stationary,lag.max = length(y_stationary),
         xlab = "lag #", ylab = 'ACF',main=' ')
# the trend signal and ACF
plot(t,y_trend,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(y_trend,lag.max = length(y_trend),
         xlab = "lag #", ylab = 'ACF', main=' ')
```

### Ljung-Box test for independence
Quantitatively, we can also use built-in test for testing stationariy. First, the Ljung-Box test examines whether there is significant evidence for non-zero correlations at given lags (1-25 shown below), with the null hypothesis of independence in a given time series (a non-stationary signal will have a low p-value).
```{r}
lag.length = 25
Box.test(y_stationary, lag=lag.length, type="Ljung-Box") # test stationary signal
```

```{r}
Box.test(y_trend,      lag=lag.length, type="Ljung-Box") # test nonstationary signal
```

# Augmented Dickey–Fuller (ADF) t-statistic test for unit root
Another test we can conduct is the Augmented Dickey–Fuller (ADF) t-statistic test to find if the series has a unit root (a series with a trend line will have a unit root and result in a large p-value).

```{r, warning=FALSE}
options(warn=-1)
library(tseries)

adf.test(y_stationary)
```

```{r}
adf.test(y_trend)
```


# Kwiatkowski-Phillips-Schmidt-Shin (KPSS) for level or trend stationarity

Lastly, we can test if the time series is level or trend stationary using the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test. Here we will test the null hypothesis of trend stationarity (a low p-value will indicate a signal that is not trend stationary, has a unit root):

```{r, warning=FALSE}
kpss.test(y_stationary, null="Trend")
```

```{r, warning=FALSE}
kpss.test(y_trend, null="Trend")
```



# Decomposing Time series data
```{r, warning=FALSE}
library(forecast)
timeserie_glu <- ts.Mar$glu_level
ts.glu <- as.ts(ts.Mar$glu_level)
#ts.glu

#tscomponents_add <- decompose(ts.Aug, type = "additive")
#tscomponents_mul <- decompose(ts.Aug, type = "multiplicative")
#plot(tscomponents_mul, col = "red")
library(fpp)
data(ausbeer)
timeserie_beer = tail(head(ausbeer, 17*4+2),17*4-4)
plot(as.ts(timeserie_beer))
trend_beer = ma(timeserie_beer, order = 4, centre = T)
plot(as.ts(timeserie_beer))
lines(trend_beer)
plot(as.ts(trend_beer))
```
#Error in decompose(timeserie_glu, type = "additive") : time series has no or less than 2 periods

## Moving Average
```{r, fig.width=20, fig.height=6}
library(forecast)
trend_glu = ma(timeserie_glu, centre = T)
plot(as.ts(timeserie_glu))
lines(trend_glu, col='red')
plot(as.ts(trend_glu))
```















































